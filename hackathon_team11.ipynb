{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon_team11",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wseungjin/2019_cau_oss_hackathon/blob/master/hackathon_team11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AosAX9DXOlc",
        "colab_type": "text"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        " *  단, 사용할 데이터셋에 따라 is_mnist만 수정\n",
        "*   모든 구현은 [2. 데이터 전처리]와 [3. 모델 생성]에서만 진행\n",
        " *  데이터 전처리 후 트레이닝, 데이터 셋은 x_train_after, x_test_after 변수명을 유지해주세요.\n",
        " *  데이터셋이 달라져도 같은 모델 구조를 유지하여야함.\n",
        "*   [4. 모델 저장]과 [5. 모델 로드 및 평가]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *  트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        " *  team_name을 제외한 다른 부분은 수정하지 말 것\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  모델 구조 파일 (model_structure_teamXX.json)\n",
        " *  모델 weight 파일 (model_weight_teamXX.h5)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        "* 제출 기한: **오후 6시**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2019_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  두 개의 데이터셋에 대해 다른 모델 구조를 사용한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lwEXhUqys1",
        "colab_type": "text"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms5PBBJ1qSC6",
        "colab_type": "code",
        "outputId": "8ec1de3e-2122-490b-9eeb-cbd692e7ffc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "is_mnist = False;\n",
        "\n",
        "# 데이터셋 로드\n",
        "# x_train, y_train: 트레이닝 데이터 및 레이블\n",
        "# x_test, y_test: 테스트 데이터 및 레이블\n",
        "if is_mnist:\n",
        "  data_type = 'mnist'\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data() # fashion MNIST 데이터셋인 경우,\n",
        "else:\n",
        "  data_type = 'cifar10'\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() # cifar10 데이터셋인 경우,\n",
        "\n",
        "\n",
        "# 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# 인풋 데이터 타입\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9c2KLDBIhNQ",
        "colab_type": "text"
      },
      "source": [
        "# **2. 데이터 전처리**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJNgjaHvIhSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = x_train / 255.0\n",
        "x_test_after = x_test / 255.0\n",
        "\n",
        "# mnist일 경우 데이터 형은 [case_num, 28,28]의 형태이다.\n",
        "# CNN에 사용하기 위해 데이터 형을 [case_num, 28, 28, 1]의 형태로 바꾸어 주어야한다.\n",
        "if is_mnist:\n",
        "  x_train_after = x_train_after.reshape(60000,28,28,1)\n",
        "  x_test_after = x_test_after.reshape(10000,28,28,1)\n",
        "  input_shape = x_train_after.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZP4eRmRqgRp",
        "colab_type": "code",
        "outputId": "a61126d8-5adf-4c02-d413-8c75c0281536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team11'\n",
        "\n",
        "\n",
        "# val_acc가 best값을 가질 경우 체크포인트로 저장한다.\n",
        "model_path = save_path +  'model_entire_' + data_type + '_' + team_name + '.h5'\n",
        "md_checkpoint = keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_acc', verbose=1, save_best_only=True)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, LeakyReLU, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "# 1st hidden layer: CNN layer\n",
        "# 초기 학습을 빠르게 하기 위하여 glorot_uniform으로 값을 초기화 한다.\n",
        "# CNN 과정 중에 shrink되기 때문에 패딩을 same으로 해준다.\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),  padding='same', input_shape=input_shape, kernel_initializer='glorot_uniform'))\n",
        "# gradient를 스무스하게 하기 위하여 BatchNormalization을 사용하였다.\n",
        "model.add(BatchNormalization())\n",
        "# gradient vanishment를 피하기 위하여 LeakyReLU를 사용하였다.\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "# 2st hidden layer: CNN layer\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "# overfitting 문제를 해결하기 위하여 Dropout 기법을 사용하였다.\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# 3st hidden layer: CNN layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "# 4st hidden layer: CNN layer\n",
        "model.add(Conv2D(64, (3,3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))      \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# 5st hidden layer: CNN layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "# 6st hidden layer: CNN layer\n",
        "model.add(Conv2D(64, (3,3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))      \n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 7st hidden layer: CNN layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "# 8st hidden layer: CNN layer\n",
        "model.add(Conv2D(64, (3,3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))    \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 9st hidden layer: CNN layer\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "# 10st hidden layer: CNN layer\n",
        "model.add(Conv2D(128, (3,3),  padding='same', kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))          \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten layer: fully connected layer에 사용하기 위하여 1D vector로 만든다.\n",
        "model.add(Flatten())\n",
        "          \n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer: fully-connected layer를 이용하여 output값을 classify한다.\n",
        "model.add(Dense(num_classes))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "model.fit(x_train_after, y_train, batch_size = 128, epochs = 200, shuffle=True, validation_data=[x_test_after, y_test],callbacks = [md_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.7368 - acc: 0.8066 - val_loss: 0.4082 - val_acc: 0.8777\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.87770, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 21s 344us/step - loss: 0.4318 - acc: 0.8849 - val_loss: 0.3371 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.87770 to 0.89320, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.3462 - acc: 0.9007 - val_loss: 0.2663 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.89320 to 0.91290, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.3003 - acc: 0.9091 - val_loss: 0.2696 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.91290\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.2736 - acc: 0.9146 - val_loss: 0.2679 - val_acc: 0.9095\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91290\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 0.2574 - acc: 0.9170 - val_loss: 0.2261 - val_acc: 0.9239\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.91290 to 0.92390, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.2370 - acc: 0.9232 - val_loss: 0.2538 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.92390\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.2291 - acc: 0.9243 - val_loss: 0.2039 - val_acc: 0.9304\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.92390 to 0.93040, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.2158 - acc: 0.9279 - val_loss: 0.2064 - val_acc: 0.9273\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.93040\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.2058 - acc: 0.9310 - val_loss: 0.2307 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.93040\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1968 - acc: 0.9342 - val_loss: 0.1965 - val_acc: 0.9317\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.93040 to 0.93170, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1890 - acc: 0.9361 - val_loss: 0.2009 - val_acc: 0.9310\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.93170\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1801 - acc: 0.9380 - val_loss: 0.1953 - val_acc: 0.9301\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.93170\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1754 - acc: 0.9401 - val_loss: 0.1920 - val_acc: 0.9337\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.93170 to 0.93370, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1720 - acc: 0.9412 - val_loss: 0.1935 - val_acc: 0.9311\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.93370\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1654 - acc: 0.9432 - val_loss: 0.2134 - val_acc: 0.9270\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.93370\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1581 - acc: 0.9459 - val_loss: 0.1933 - val_acc: 0.9334\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.93370\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1542 - acc: 0.9472 - val_loss: 0.1809 - val_acc: 0.9361\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.93370 to 0.93610, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1475 - acc: 0.9496 - val_loss: 0.1854 - val_acc: 0.9379\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.93610 to 0.93790, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1448 - acc: 0.9507 - val_loss: 0.1956 - val_acc: 0.9348\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.93790\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.1409 - acc: 0.9512 - val_loss: 0.1830 - val_acc: 0.9345\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.93790\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1383 - acc: 0.9522 - val_loss: 0.1928 - val_acc: 0.9376\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.93790\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1322 - acc: 0.9546 - val_loss: 0.2037 - val_acc: 0.9340\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.93790\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1262 - acc: 0.9560 - val_loss: 0.1863 - val_acc: 0.9368\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.93790\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1246 - acc: 0.9568 - val_loss: 0.2201 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.93790\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.1205 - acc: 0.9586 - val_loss: 0.1993 - val_acc: 0.9365\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.93790\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1184 - acc: 0.9595 - val_loss: 0.1829 - val_acc: 0.9390\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.93790 to 0.93900, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.1136 - acc: 0.9604 - val_loss: 0.1846 - val_acc: 0.9394\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.93900 to 0.93940, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1096 - acc: 0.9631 - val_loss: 0.1844 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.93940 to 0.94070, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.1081 - acc: 0.9625 - val_loss: 0.1783 - val_acc: 0.9418\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.94070 to 0.94180, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.1031 - acc: 0.9646 - val_loss: 0.1961 - val_acc: 0.9389\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.94180\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0995 - acc: 0.9661 - val_loss: 0.1803 - val_acc: 0.9410\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.94180\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.1001 - acc: 0.9658 - val_loss: 0.1823 - val_acc: 0.9434\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.94180 to 0.94340, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0943 - acc: 0.9682 - val_loss: 0.1794 - val_acc: 0.9426\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.94340\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0907 - acc: 0.9685 - val_loss: 0.1850 - val_acc: 0.9414\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.94340\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 0.0908 - acc: 0.9687 - val_loss: 0.1855 - val_acc: 0.9395\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.94340\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0867 - acc: 0.9705 - val_loss: 0.1858 - val_acc: 0.9421\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.94340\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0863 - acc: 0.9697 - val_loss: 0.1828 - val_acc: 0.9434\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.94340\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.0843 - acc: 0.9709 - val_loss: 0.1948 - val_acc: 0.9429\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.94340\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0791 - acc: 0.9728 - val_loss: 0.1992 - val_acc: 0.9421\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.94340\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0770 - acc: 0.9732 - val_loss: 0.1978 - val_acc: 0.9413\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.94340\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0760 - acc: 0.9743 - val_loss: 0.1959 - val_acc: 0.9418\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.94340\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 0.0726 - acc: 0.9751 - val_loss: 0.2047 - val_acc: 0.9410\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.94340\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0741 - acc: 0.9744 - val_loss: 0.2164 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.94340\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0707 - acc: 0.9752 - val_loss: 0.2007 - val_acc: 0.9398\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.94340\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0675 - acc: 0.9767 - val_loss: 0.2110 - val_acc: 0.9406\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.94340\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0650 - acc: 0.9771 - val_loss: 0.2065 - val_acc: 0.9430\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.94340\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0643 - acc: 0.9776 - val_loss: 0.2106 - val_acc: 0.9421\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.94340\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0615 - acc: 0.9785 - val_loss: 0.2107 - val_acc: 0.9433\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.94340\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0611 - acc: 0.9779 - val_loss: 0.2134 - val_acc: 0.9420\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.94340\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.0588 - acc: 0.9797 - val_loss: 0.2098 - val_acc: 0.9444\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.94340 to 0.94440, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0571 - acc: 0.9801 - val_loss: 0.2145 - val_acc: 0.9437\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.94440\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0581 - acc: 0.9797 - val_loss: 0.2198 - val_acc: 0.9425\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.94440\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0574 - acc: 0.9800 - val_loss: 0.2164 - val_acc: 0.9417\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.94440\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0526 - acc: 0.9819 - val_loss: 0.2119 - val_acc: 0.9432\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.94440\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0531 - acc: 0.9819 - val_loss: 0.2276 - val_acc: 0.9395\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.94440\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0504 - acc: 0.9826 - val_loss: 0.2261 - val_acc: 0.9413\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.94440\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0514 - acc: 0.9817 - val_loss: 0.2320 - val_acc: 0.9429\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.94440\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0509 - acc: 0.9824 - val_loss: 0.2242 - val_acc: 0.9431\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.94440\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0503 - acc: 0.9821 - val_loss: 0.2312 - val_acc: 0.9426\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.94440\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 0.0495 - acc: 0.9825 - val_loss: 0.2393 - val_acc: 0.9387\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.94440\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0460 - acc: 0.9838 - val_loss: 0.2296 - val_acc: 0.9391\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.94440\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0450 - acc: 0.9846 - val_loss: 0.2350 - val_acc: 0.9442\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.94440\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0428 - acc: 0.9847 - val_loss: 0.2267 - val_acc: 0.9429\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.94440\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0412 - acc: 0.9860 - val_loss: 0.2269 - val_acc: 0.9433\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.94440\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 0.0445 - acc: 0.9842 - val_loss: 0.2367 - val_acc: 0.9427\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.94440\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0438 - acc: 0.9848 - val_loss: 0.2478 - val_acc: 0.9419\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.94440\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0384 - acc: 0.9869 - val_loss: 0.2427 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.94440\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0397 - acc: 0.9865 - val_loss: 0.2369 - val_acc: 0.9409\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.94440\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0395 - acc: 0.9861 - val_loss: 0.2388 - val_acc: 0.9439\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.94440\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0395 - acc: 0.9865 - val_loss: 0.2552 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.94440\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0377 - acc: 0.9870 - val_loss: 0.2419 - val_acc: 0.9420\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.94440\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0378 - acc: 0.9870 - val_loss: 0.2403 - val_acc: 0.9426\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.94440\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 21s 344us/step - loss: 0.0381 - acc: 0.9862 - val_loss: 0.2397 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.94440\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0355 - acc: 0.9882 - val_loss: 0.2855 - val_acc: 0.9339\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.94440\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0350 - acc: 0.9880 - val_loss: 0.2498 - val_acc: 0.9448\n",
            "\n",
            "Epoch 00076: val_acc improved from 0.94440 to 0.94480, saving model to /content/best_model_mnist_team11.h5\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0359 - acc: 0.9876 - val_loss: 0.2505 - val_acc: 0.9411\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.94480\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0342 - acc: 0.9880 - val_loss: 0.2511 - val_acc: 0.9419\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.94480\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0348 - acc: 0.9877 - val_loss: 0.2441 - val_acc: 0.9434\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.94480\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0340 - acc: 0.9884 - val_loss: 0.2413 - val_acc: 0.9409\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.94480\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 0.0328 - acc: 0.9884 - val_loss: 0.2565 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.94480\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0324 - acc: 0.9888 - val_loss: 0.2793 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.94480\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0321 - acc: 0.9895 - val_loss: 0.2554 - val_acc: 0.9422\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.94480\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0321 - acc: 0.9888 - val_loss: 0.2608 - val_acc: 0.9431\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.94480\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0321 - acc: 0.9887 - val_loss: 0.2547 - val_acc: 0.9436\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.94480\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0303 - acc: 0.9899 - val_loss: 0.2633 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.94480\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0291 - acc: 0.9897 - val_loss: 0.2715 - val_acc: 0.9394\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.94480\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 21s 345us/step - loss: 0.0326 - acc: 0.9886 - val_loss: 0.2758 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.94480\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0308 - acc: 0.9892 - val_loss: 0.2668 - val_acc: 0.9435\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.94480\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0306 - acc: 0.9896 - val_loss: 0.2693 - val_acc: 0.9425\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.94480\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0282 - acc: 0.9904 - val_loss: 0.2684 - val_acc: 0.9398\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.94480\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0283 - acc: 0.9899 - val_loss: 0.2652 - val_acc: 0.9432\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.94480\n",
            "Epoch 93/200\n",
            "39808/60000 [==================>...........] - ETA: 6s - loss: 0.0276 - acc: 0.9904"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-6a1cde718843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# validation_data: 중간 성능 검증에 사용할 data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_after\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test_after\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmd_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR9WUYXxqtfR",
        "colab_type": "text"
      },
      "source": [
        "# **4. 최고의 모델을 가져와 웨이트값과 모델의 구조를 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi9yznz4qvzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team11'\n",
        "\n",
        "# 최고의 모델을 불러와 웨이트값과 모델의 구조를 저장할 준비를 하기 위해 불러옵니다.\n",
        "newmodel = keras.models.load_model(save_path + 'model_entire_' + data_type + '_' + team_name + '.h5')\n",
        "\n",
        "\n",
        "# 모델의 weight 값만 저장합니다.\n",
        "newmodel.save_weights(save_path + 'model_weight_' + data_type + '_' + team_name + '.h5')\n",
        "\n",
        "# 모델의 구조만을 저장합니다.\n",
        "model_json = newmodel.to_json()\n",
        "with open(save_path + 'model_structure_' + data_type + '_' + team_name + '.json', 'w') as json_file : \n",
        "    json_file.write(model_json)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B2BoRDZ7cFl",
        "colab_type": "text"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDBwxVUx7knQ",
        "colab_type": "code",
        "outputId": "420ebd1a-2454-4cde-b0e9-bc55dcc230be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team11'\n",
        "\n",
        "#평가합니다\n",
        "model = keras.models.load_model(save_path + 'model_entire_'+ data_type + '_' + team_name + '.h5')\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c1bf2c63e204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#평가합니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model_entire_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mteam_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_after\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m       h5py is not None and (\n\u001b[1;32m    145\u001b[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/model_entire_cifar10_team11.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSgqEQ13mgG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}